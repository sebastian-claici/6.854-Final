
%%% Local Variables:
%%% mode: latex
%%% TeX-master: t
%%% End:

\documentclass[11pt]{article}

\usepackage{booktabs}
\usepackage{framed}
\usepackage{fullpage}
\usepackage{parskip}

% Figures
\usepackage{subfig}

% Maths
\usepackage{amsmath,amssymb,amsthm}

\newtheorem{theorem}{Theorem}[section]
\newtheorem{corollary}{Corollary}[theorem]
\newtheorem{lemma}[theorem]{Lemma}

% Algorithms
\usepackage[noend]{algpseudocode}
\usepackage{algorithm}

% TikZ
\usepackage{tikz}

\usetikzlibrary{arrows,topaths,calc,shapes,through,intersections}

\tikzstyle{vertex}=[circle,fill=black,minimum size=10pt,inner sep=0pt]
\tikzstyle{dual}=[draw,circle,minimum size=10pt,inner sep=0pt]
\tikzstyle{edge} = [draw,very thick,-]
\tikzstyle{weight} = [font=\small]

\newcount\mycount

% Other
\newcommand{\ra}[1]{\renewcommand{\arraystretch}{#1}}

\title{Single-Source Shortest Paths in Planar Graphs}
\author{Stuart Baker, \"{O}mer Cerraho\u{g}lu, Sebastian Claici}
\date{}

\begin{document}
\maketitle

\begin{abstract}
  We survey advances in single-source shortest paths algorithms on the special case of planar graphs. For the case of non-negative edge weights, we show $\mathcal{O}(n\log \log n)$ algorithm and provide intuition for an optimal $\mathcal{O}(n)$ algorithm. For arbitrary edge weights, we give an $\mathcal{O}(n\log^2 n)$ algorithm and show how to modify it to achieve $\mathcal{O}(n\log^2 n/\log \log n)$.
\end{abstract}

\section{Introduction}
\label{sec:introduction}

Finding shortest paths in graphs is one of the oldest combinatorial optimization problems. At least in the sense of path finding, there are references dating back to the late 1800's~\cite{wiener1873ueber}. The standard algorithm for single-source shortest paths on a graph with no negative edge weights is Dijkstra's algorithm~\cite{dijkstra1959note}.

While for general graphs the problem has been effectively solved decades ago, for the special case where the graph is planar has seen a number of surprising developments in recent years. We enumerate these here, and detail them in later sections.

For directed graphs where the edge weights are non-negative, the first improvement over $\mathcal{O}(n\log n)$ came from Federickson who gave a $\mathcal{O}(n \sqrt{\log n}$) bound~\cite{federickson1987fast}. This was improved nearly a decade later by Henzinger et al.\ to linear time~\cite{henzinger1997faster}. We remark that for general \emph{undirected} graphs with positive edge weights, there are known linear time algorithms for single-source shortest paths in the RAM model~\cite{thorup1999undirected}.

For directed graphs with arbitrary edge weights, there have been recent developments that greatly improve upon a naive $\mathcal{O}(n^2)$ Bellman-Ford. In 2010, Klein, Mozes and Weimann gave a $\mathcal{O}(n \log^2 n)$ algorithm~\cite{klein2010shortest}, which was improved to $\mathcal{O}(n \log^2 n / \log \log n)$ shortly thereafter~\cite{mozes2010shortest}. Both algorithms make use of a $\mathcal{O}(n \log n)$ multiple-source shortest paths algorithm due to Klein~\cite{klein2005multiple}.

The goal of this paper is to provide intuition into some of the recent developments in planar graph theory.

This paper is organized as follows: in section~\ref{sec:background} we provide background on the theorems we will need later on; in section~\ref{sec:graph-sep} we detail planar graph separators which are used extensively in divide-and-conquer planar graph algorithms. In sections~\ref{sec:nonn-edge-weights}~and~\ref{sec:arbitr-edge-weights} we detail faster algorithms for single-source shortest paths in graphs with non-negative, respectively arbitrary edge weights.

\section{Background}
\label{sec:background}

We assume the reader is familiar with basic graph theory. Planar graphs are graphs that can be drawn in Euclidean space such that no two edges cross each other. Every drawing of a planar graph delineates several faces, one of which is unbounded and represents the ``outside'' of the graph; we call this face the infinite face, and denote it by $f_{\infty}$. The following theorems are used implicitly or explicitly throughout the paper.\\

\begin{theorem}[Jordan curve theorem]
  Let $C$ be any closed curve in the plane. Removal of $C$ divides the plane into exactly two connected regions, the ``inside'' and the ``outside'' of $C$.
\end{theorem}

An interesting proof of the Jordan curve theorem that uses the non-planarity of the complete bipartite graph on two sets of 3 edges ($K_{3,3}$ shown in figure~\ref{fig:kuratowski}b) was given in~\cite{thomassen1992jordan}.\\

\begin{theorem}[Euler's formula for planar graphs]
  If $n$ is the number of nodes, $m$ the number of edges, and $f$ the number of faces of a planar graph, the following formula holds:
\[
  n - m + f = 2.
\]
\end{theorem}

From Euler's formula, we can quickly prove a bound on the number of edges in a planar graph:\\

\begin{theorem}
  Any $n$-vertex planar graph with $n \geq 3$ contains no more than $3n-6$ edges.\\
\end{theorem}

\begin{theorem}[Kuratowski's theorem]
  A graph is planar if and only if it contains neither a complete graph on five vertices, nor a complete bipartite graph on two sets of three vertices as a generalized subgraph.
\end{theorem}

An in-depth discussion of Kuratowski's theorem and a short proof are found in~\cite{thomassen1981kuratowski}. The Kuratowski subgraphs are shown in figure~\ref{fig:kuratowski}. An immediate corollary of Kuratowski's theorem is that we can shrink edges and subgraphs while preserving planarity.\\

\begin{corollary}
  Shrinking any edge of a planar graph to a single vertex preserves planarity. Applying this inductively, shrinking any subgraph to a single vertex preserves planarity.\\
\end{corollary}

\begin{figure}[!htb]
  \centering
  \subfloat[]{
    \begin{tikzpicture}[scale=0.2]
      \foreach \ang/\id in {18/1,90/2,162/3,234/4,306/5}{
        \node[vertex] (\id) at (\ang:5) {};
      }
      \foreach \number in {1,...,4}{
        \mycount=\number
        \advance\mycount by 1
        \foreach \numbera in {\the\mycount,...,5}{
          \path[edge] (\number) edge (\numbera);
        }
      }

    \end{tikzpicture}
  }\hfil
  \subfloat[]{
    \begin{tikzpicture}[scale=0.2]
      \node at (0,-1) {};
      \foreach \x/\id in {-4/1,0/2,4/3}{
        \node[vertex] (\id) at (\x,0) {};
      }
      \foreach \x/\id in {-4/4,0/5,4/6}{
        \node[vertex] (\id) at (\x,5) {};
      }

      \foreach \x in {1,2,3}{
        \foreach \y in {4,5,6}{
          \path[edge] (\x) -- (\y);
        }
      }

    \end{tikzpicture}
  }
  \caption{Kuratowski subgraphs. (a) $K_5$, (b) $K_{3,3}$}
  \label{fig:kuratowski}
\end{figure}


\begin{theorem}
  Every planar graph can be embedded without edge crossings on a sphere. As a corollary, every node $v$ of a planar graph can be embedded on the boundary of the infinite face $f_{\infty}$.
\end{theorem}

A stereographic projection can be used to embed nodes on a plane onto a sphere without edge crossings (see figure~\ref{fig:stereo}).

\begin{figure}[!htb]
  \centering
  \begin{tikzpicture}[scale=0.6]
    \draw (-4,0) -- (4,0);

    \coordinate (aux) at (0,0);
    \coordinate (z) at (0,4);
    \coordinate (a) at (2,0);
    \coordinate (b) at (0,2);
    \coordinate (d) at (-3.5,0);

    \node (A) [label=270:$a$] at (a) {$\bullet$};
    \node (D) [label=270:$b$] at (d) {$\bullet$};
    \node (Z) at (z) {$\bullet$};

    \node (circ) at (b) [draw,circle through=(aux)] {};
    \coordinate (az) at (intersection 1 of circ and z--a);
    \coordinate (dz) at (intersection 1 of circ and z--d);

    \draw (a) -- (z);
    \draw (d) -- (z);

    \node (xx) [label=90:$a'$] at (az) {\color{red}$\bullet$};
    \node (yy) [label=100:$b'$] at (dz) {\color{red}$\bullet$};

  \end{tikzpicture}
  \caption{Stereographic projection of two points on a line onto a circle.}
  \label{fig:stereo}
\end{figure}

Finally, specifically for shortest paths algorithms, we note the following:\\

\begin{theorem}
  A planar graph on $n$ nodes can be transformed by adding $\mathcal{O}(n)$ nodes and edges into another planar graph such that every node has in- and out-degree at most $2$.
\end{theorem}

\section{Planar Graph Separators}
\label{sec:graph-sep}

    % TODO Miller's Algorithm
    % TODO Last point in Tarjan's algorithm


    For large planar graphs, a common approach to solving a specific problem is to take a divide-and-conquer approach. The core problem in divide-and-conquer problems is finding a way to divide the problem space into smaller spaces and recurse until we reach a subspace that is small enough to allow for effective computation. The results at the lowest level are then rolled back up through the recursion to give the final answer.

    \subsection{Fundamental Cycle Separators}
    \label{sec:graph-sep-fund-cycle-sep}

    One method for dividing a planar graph into smaller set was developed by Lipton and Tarjan called the fundamental cycle separator~\cite{lipton1979separator}. Lipton and Tarjan showed that for any planar graph $G = (V,E)$ on $n = |V|$ vertices, and for any weight function $w: V \rightarrow \mathbb{R}^+$, it is possible to partition the nodes of the graph into three sections $A, B$ and $C$ such that
    \begin{itemize}
        \item $w(A), w(B) \leq \alpha \cdot w(V)$ for some $\alpha \in (0,1)$

        \item There are no edges between nodes in $A$ and nodes in $B$.

        \item The size of the separator $S$ is small. In particular, we can achieve $|S| = \mathcal{O}(\sqrt{n})$.
    \end{itemize}

    For a root vertex $r$, we can build a spanning tree of the graph $G$ that has depth $d$. We define $T^*$ as the dual tree of the triangulated version of $G$. From this tree, every non-tree edge $e$ defines a fundamental cycle $C(e)$. Since the depth of $T$ is at most $d$, we know that $|C(e)| \leq 2d + 1$. However, because the diameter of $G$ may be large, we want to reduce it so that we can constrain $|C(e)| \leq \sqrt{n}$. Central to developing this better partition is the ability to divide the planar graph into levels.

Given some $n$-vertex planar graph $G$ with nonnegative vertex costs, it is possible to partition the vertices of the graph based on their distance from a vertex $v$. One method for finding this partitioning is to run a breadth-first search from $v$. Given the partitioning, define $L(l)$ as the number of vertices on the level $l$. The levels range from $0$ to $r$ where $r$ is the maximum distance from $v$ to any vertex in the graph. For the algorithm to work, an additional empty level must be added at $r+1$.

    The algorithm is as follows:
    \begin{enumerate}

        \item Find the most costly component in the graph and run a depth-first search from this graph. This calculates the level of each vertex in the graph. Find the maximum depth $r$ in the level tree, and add an additional level at $r+1$ that contains no vertices. This step can be performed in $\mathcal{O}(n)$.

        \item Find the level $i_0$ that contains the median vertex. This is the level where
\[
\sum_{i \leq i_0} |L_i(v)| \geq \frac{n}{2} \quad \text{and}\quad \sum_{i \geq i_0} |L_i(v)| \geq \frac{n}{2}.
\]
This step can be performed in $\mathcal{O}(n)$.n

        \item Find levels $i_- \leq i_0 \leq i_+$ such that the number of vertices on levels $i_-$ and $i_+$ is less than $\sqrt{n}$. Note that any level
        \begin{itemize}
            \item Start from the median vertex containing level $i_0$ and increase $i_+$ as well as decrease $i_-$ until $|L_{i_-}|,|L_{i_+}| \leq \sqrt{n}$

            \item Because each section can only contain half of the vertices, we can use the counting argument to state that $|i_0 - i_-|,|i_+ - i_0| \leq \frac{\sqrt{n}}{2}$

            \item This gives a separator $|L_{i_-} \cup L_{i_+}| \leq 2 \sqrt{n}$, which we can return if the grouping of $L_{< i_-}$, $L_{> i_+}$, and $L_{i_-,i_+}$ is balanced.
        \end{itemize}
        If the grouping is not balanced, continue to step $4$.

        \item Form a condensed graph $G^{'}$ by deleting  all edges in $L_{\geq i_+}$, and contracting all edges in $L_{\leq i_-}$ into a super vertex $v$ that is connected to all vertices in $L_{i_- + 1}$.

        \item From the condensed graph $G^{'}$, create a fundamental cycle separator $S$
        \begin{itemize}
            \item Build a breadth-first tree from $v$. This tree will have depth $|i_+ - i_-| \leq \sqrt{n}$

            \item Add edges to the tree such that each face (except $f_{\infty}$) is a triangle.
        \end{itemize}

        \item Start with any non-tree edge $uv$, and walk along the BFS tree in both directions until a cycle is formed. This cycle is the current separator candidate. Determine which side of the cycle has greater weight and call it the ``inside''.

        \item If the weight of the ``inside'' is larger than $2/3$, fix the cycle by changing $uv$ with another non-tree edge. We can ensure that the weight of the ``inside'' will only decrease during this process. Repeat this step until a suitable cycle separator has been found.

        \item Using this separator, return $A$ and $B$ as some combination of int$(C)$, ext$(C)$, $L_{< i_-}$, and $L_{> i_+}$. $S$ can be returned as a combination of $L_{i_-}$, $L_{i_+}$, and $C$.

    \end{enumerate}

    \subsection{Miller's Algorithm}
    \label{sec:graph-sep-miller}

    Miller showed an alternative method for separating a planar graph into two sections with a separator region. He showed that every 2-connected triangulated planar graph with $n$ vertices has a simple cycle $C$ of length at most $4\sqrt{n}$~\cite{miller1984finding}. Like Lipton and Tarjan's algorithm, Miller's algorithm produces two sets, $A$ and $B$, each of which with no more than $\frac{2}{3}n$ vertices. Miller's Algorithm consists of two distinct phases:
    \begin{enumerate}
      \item Find a subgraph $H$ of the parent planar graph $G$ that has a diameter of $\sqrt{n}$ and a face size of $\sqrt{n}$

      \item Find a separator contained in $H$
    \end{enumerate}

    % Given that we now have the subgraph $H$ with radius $\sqrt{d \cdot n}$ from the parent graph $G$, we now have to find the separator within $H$.
    % \begin{theorem}
    %   If $G_\phi$is a 2-connected embedded planar graph with spanning tree $T$, then there exists a simple cycle weight separator of size at most $d + S$ with no face weight $> \frac{2}{3}$. Where $d$ is the diameter of $T$, and $S$ is the maximum face size.
    % \end{theorem}

    % We can start with the spanning tree $T$ of the graph $G$. If we say that $e$ is any non-tree edge, then $C_e$ is the induced simple cycle in the spanning tree $T$. Furthermore, let $F$ be the face common to $e$ on the interior of $C_e$. We can expand this by saying that $C_i$ is the cycle induced by $e_i$ such that $int(C_i)$ is contained within $int(C_e)$.

    % \begin{lemma}
    %   Either there exists an $i$ such that $F + C_i$ us a weighted separator, or there exists an $i$ such that $\#(int(F + C_i)) > \frac{2}{3}$ and for all $j$, such that $\overline{C}_j$ is a child of $\overline{C}_i$, $\#(ext(F + C_j)) > \frac{2}{3}$.
    % \end{lemma}

    Shrinking the diameter of the graph consists of finding the heaviest child in a breadth-first search tree and collapsing all of the face of the graph outside of a certain size bound from that child.
    \begin{enumerate}
      \item From the original graph $G$, construct its primal $G^{'}$.

      \item Build a breadth-first search tree starting from some root $r$.

      \item Find the heaviest subtree in the BFS tree by following the heaviest child until you reach a cycle $C_0$ with weight $> \frac{1}{2}$, but where all enclosed cycles have weight $< \frac{1}{2}$.

      \item Find the level $i_-$ higher in the BFS tree than $i_0$ that has a boundary size of $\mathcal{\sqrt{n}}$. From this level, choose a cycle $C_r$ that encompases $C_0$.

      \item Find the level $i_+$ lower in the BFS tree than $i_0$ that has  a boundary size of $< \mathcal{\sqrt{n}}$.

      \item Find the lower-diameter primal graph $G^{'}$.
      \begin{itemize}
        \item Merge all of the faced enclosed by $C$ for all of the cycles $C$ in $L_+$ enclosed by $C_0$.

        \item All of the faces not enclosed by $C_r$ can be merged together.

        \item $G^{'}$ now has a diameter of$\mathcal{O}(\sqrt{n}$.
      \end{itemize}
    \end{enumerate}

    After diameter reduction, the next step is to find the separator within the subgraph.
    \begin{enumerate}
      \item Compute the spanning tree $T^{'}$ of the graph $G^{'}$.

      \item Apply the fundamental cycle separator lemma to $G^{'}$ with $T^{'}$ to break the graph apart.
    \end{enumerate}

    \subsection{r-Subdivision}
    \label{sec:graph-sep-rsub}

    A division into $2$ regions is not useful for a divide-and-conquer approach. Fortunately, we can achieve an $r$-segmentation of the graph into $\Theta \left (\frac{n}{r} \right )$ regions, each with $\mathcal{O}(r)$ vertices, and separated by $\mathcal{O} \left (\frac{n}{\sqrt{r}} \right )$ boundary vertices. Federickson takes this definition a step further and defines a \textit{suitable} r-division of a planar graph as the r-division that satisfies two characteristics~\cite{federickson1987fast}:
    \begin{enumerate}
        \item Each boundary vertex is contained in at most three regions

        \item Any region that is not connected consists of connected components, all of which share boundary vertices with exactly the same set of either one or two connected regions.
    \end{enumerate}
A suitable $r$-division is shown in figure~\ref{fig:rsep}.

    \begin{figure}[!htb]
      \centering
      \includegraphics[width=.5\textwidth]{rsep}
      \caption{Planar graph separated into $r$ regions. From~\cite{federickson1987fast}.}
      \label{fig:rsep}
    \end{figure}

    Starting with the initial graph $G$, all of the vertices are in the interior region. A separator algorithm can then be applied to the graph with all of the vertex weights set to $\frac{1}{n}$. This will produce three sets: $A$, $B$, and $C$. From these two sets, we can infer two regions that have the vertex sets $A_1 \subseteq A \cup C$ and $A_2 \subseteq B \cup C$. These two vertex sets will have sizes $\alpha n + \mathcal{O}\sqrt{n}$ and $(1 - \alpha) n + \mathcal{O}\sqrt{n}$ with $\frac{1}{3} \leq \alpha \leq \frac{2}{3}$. To continue the process, the separator algorithm can be recursively applied to any region that has more than $r$ vertices. The total runtime of this algorithm is $\mathcal{O} \left (n \log \left (\frac{n}{r} \right ) \right )$.

\textcolor{red}{TODO: $r$-separators can be found in $\mathcal{O}(n\log r)$ time. Detail this algorithm. Provide intuition on how to go from that to $\mathcal{O}(n)$ time.}

\section{Single source shortest paths with non-negative edge weights}
\label{sec:nonn-edge-weights}

The fastest algorithm for single-source shortest paths in general graphs with non-negative edge weights is Dijkstra's algorithm which runs in time $\mathcal{O}(m + n\log n)$. Planar graphs are sparse, so simply applying Dijkstra's algorithm on a planar graph already yields an $\mathcal{O}(n \log n)$ algorithm.

We can do much better by using the ideas developed in section~\ref{sec:graph-sep}.

\subsection{Simple algorithm}
\label{sec:simple-algorithm}

A simple $\mathcal{O}(n\sqrt{\log n \log \log n})$ emerges beautifully from an $r$-division if we set $r = \log n/\log \log n$. The first step is to compute the single-source shortest paths for each boundary node in each region $R$. As customary, we use $s$ for the source node throughout this section.


\begin{algorithm}[!htb]
  \refstepcounter{algorithm}
  \label{alg:sssp-region}
  \begin{algorithmic}
    \ForAll {Regions $R$}
      \ForAll {Boundary nodes $v \in R$}
        \State Compute SSSP from $v$ in $R$
        \State Store $(u,v)$ distances for any two boundary nodes $u$, $v$
      \EndFor
    \EndFor
  \end{algorithmic}
\end{algorithm}

 We can now replace each region $R$ by a complete graph on $R$'s boundary nodes with shortest paths distances between any two nodes. Call this auxiliary graph $G'$. The second phase of the algorithm is to compute the SSSP from $s$ in $G'$. This gives the true shortest paths from $s$ to all the boundary nodes. Finally, we must tidy up by finding the distances from $s$ to the nodes inside each region.

\begin{algorithm}[!htb]
  \refstepcounter{algorithm}
  \label{alg:sssp-full}
  \begin{algorithmic}
    \ForAll {Regions $R$}
      \ForAll {Boundary nodes $v \in R$}
        \State Set $d(v) = d_{G'}(s,v)$
        \State Compute SSSP from $v$ in $R$
      \EndFor
    \EndFor
  \end{algorithmic}
\end{algorithm}

To analyze the algorithm, recall the properties of an $r$-division.
\begin{itemize}
\item Total number of boundary nodes is $\mathcal{O}(n/\sqrt{r})$.
\item Number of nodes in $G'$ is $\mathcal{O}(n/r)O(\sqrt{r})=O(n/\sqrt{r})$.
\item Number of edges in $G'$ is $\mathcal{O}(n/r)\mathcal{O}(r) = \mathcal{O}(n)$.
\end{itemize}

Using $r=\frac{\log n}{\log \log n}$, the first phase is bounded above by
\[
  O\left(n\frac{\sqrt{\log \log n}}{\sqrt{\log n}} \log n\right)= O(n \sqrt{\log n \log \log n}),
\]
the second phase is an SSSP in a size $\mathcal{O}(n \frac{\sqrt{\log \log n}}{\sqrt{\log n}})$ graph, and thus also $\mathcal{O}(n \sqrt{\log n \log \log n})$, while the tidying up is a series of SSSPs in each of the regions, and has the same bound as the first phase---$\mathcal{O}(n \sqrt{\log n \log \log n})$. The total time bound ends up $\mathcal{O}(n \sqrt{\log n \log \log n})$.

\subsection{Recursive subdivisions}
\label{sec:recursion}

We have improved upon Dijkstra's algorithm, but there is still room to do better. A recursive subdivision $\bar{r} = (r_0, \ldots, r_h)$ of a graph is a division in which the regions are subdivided recursively up to edges. A region at level $i$ is sub-divided into regions of size $r_{i-1}$. The regions at level $0$ are called atomic and contain only one edge $uv$.

For each region $R$, we maintain a priority queue $Q(R)$ that stores the subregions of $R$ if $R$ is nonatomic, or the single arc $uv$ is $R$ is atomic. We call and edge $uv$ \emph{active} if its head $v$ has a finite distance label $d(v)$, and \emph{inactive} if $d(v)$ is infinite. During execution, edges can change status from \emph{active} to \emph{inactive} several times. The algorithm ensures that for every region $R$, the minimum element of $Q(R)$ is the minimum label $d(v)$ over all edges $vw$ in $R$ that remain to be processed.

We would like to apply Dijkstra's until completion in each region, and somehow bubble up the results on lower levels. Unfortunately, this idea does not lead to a faster algorithm. Instead, we try to work mostly on the lower levels and perform speculative work. The algorithm tries to ensure that, on average, the operations on large queues can be paid for by the many operations performed on small queues.

\begin{algorithm}
  \refstepcounter{algorithm}
  \label{alg:linear}
  \begin{algorithmic}[1]
    \State Find recursive subdivision $R(G), R(P_i), \ldots, R(uv)$
    \State Allocate queue $Q$ for each region
    \State $d(v) \gets \infty, \forall v$
    \State $d(s) \gets 0$
    \ForAll {$sv \in E(G)$}
      \State \Call{Update}{$R(sv),sv,0$}
    \EndFor
    \While {$Q(R(G)).minKey() < \infty$}
      \State \Call{Process}{$R(G)$}
    \EndWhile
  \end{algorithmic}
\end{algorithm}

Each call to \textsc{Process} is effectively an invocation of Dijkstra's algorithm. If we're at the level of an edge, we try to relax that edge. Otherwise, we recursively call \textsc{Process} on the current best subregion to explore further.

\begin{algorithm}[!h]
  \label{alg:process}
  \begin{algorithmic}[1]
    \Procedure{Process}{}
      \If {$R$ contains only $uv$}
        \If {$d(v) > d(u) + c(u,v)$}
          \State $d(v) \gets d(u) + c(u,v)$
          \State for each outgoing edge $vw$ of $v$, call \Call{Update}{$R(vw),vw,d(v)$}
        \EndIf
        \State $Q(R).updateKey(uv,\infty)$
      \Else
        \Repeat
          \State $R' \gets Q(R).getMin()$
          \State \Call{Process}($R'$)
          \State $Q(R).updateKey(R',Q(R').minKey())$
        \Until {$Q(R).minKey()$ is infinity or if repeated $\alpha_{h(R)}$ times}
      \EndIf
    \EndProcedure
  \end{algorithmic}
\end{algorithm}

The calls to \textsc{Update} ensure that the information in parent regions stays consistent with work done at lower regions by bubbling up key updates that result in a new minimum.

\begin{algorithm}[!h]
  \label{alg:update}
  \begin{algorithmic}[1]
    \Procedure{Update}{$R,x,k$}
      \State $Q(R).updateKey(x,k)$
      \If {$updateKey$ reduced the value of $Q(R).minKey()$}
        \State \Call{Update}{$parent(R),R,k$}
      \EndIf
    \EndProcedure
  \end{algorithmic}
\end{algorithm}

Unlike Dijkstra's algorithm, the work we do in a region is only speculative. Often we cannot afford to fully process a region, and executions are stopped after a fixed number of steps. Specifically, at level $i$, we perform $\alpha_i$ steps of Dijkstra's algorithm, where the $\alpha_i$ are parameters that will dictate the running time of the algorithm.

\subsubsection{Correctness}
\label{sec:correctness}

Recall from Dijkstra's algorithm that three properties imply correctness:
\begin{enumerate}
\item Initialization: $d(s) = 0$.
\item Minimum length property: $d(v)$ is an upper bound on the $s$ to $v$ distance
\item All edges are relaxed. We call an edge $uv$ is relaxed if $d(v) \leq d(u) + c(u,v)$.
\end{enumerate}

The first property is true at the start of the algorithm, and remains true throughout. The following lemma establishes the second property:\\

\begin{lemma}
  For each node $v$, $d(v)$ is an upper bound on the distance from $s$ to $v$ throughout the algorithm.
\end{lemma}

\begin{proof}
  Initially, all labels except $d(s)$ are infinity. The labels only get changed in line $4$ of \textsc{Process}, and assuming inductively that the old labels $d(v)$ and $d(u)$ are upper bounds on the distance to $u$ and $v$, it follows that the new labels will also be upper bounds.
\end{proof}

The following three lemmas establish the third property.\\

\begin{lemma}
  If an edge $uv$ is inactive then it is relaxed.
\end{lemma}

\begin{proof}
  The lemma holds before the first call to \textsc{Process} as every node but $s$ has label infinity and outgoing edges from $s$ are active. Edges are deactivated only in line $7$ of \textsc{Process} which occurs only after the edge has been relaxed.

  Note that it is possible that an edge becomes unrelaxed after changes to the labels of its endpoints. This can occur for a call to \textsc{Update}, but line $2$ of \textsc{Update} changes the key of the edge, making it active again.
\end{proof}

\begin{lemma}
  The key of an active edge $uv$ is $d(u)$ (except during lines $3-6$ of \textsc{Process}).
\end{lemma}

\begin{proof}
  Whenever a label $d(u)$ is assigned a value $k$, \textsc{Update}$(R(uv),uv,k)$ is called for each outgoing edge $uv$, and the key of $uv$ is updated to $k$.
\end{proof}

\begin{lemma}
  \label{lemma:invariant}
  For any region $R$ that is not an ancestor of the current region, the key associated with $R$ in $Q(parent(R))$ is the minimum key of $Q(R)$.
\end{lemma}

\begin{proof}
  Whenever the minimum key of a queue $Q(R)$ is changed in line $2$ of \textsc{Update}, the recursive call in line $4$ ensures that the key associated with $R$ in the parent of $R$ is also changed.
\end{proof}

From lemma~\ref{lemma:invariant}, the following corollary follows:\\

\begin{corollary}
\label{cor:relaxed}
  For any region $R$ that is not an ancestor of the current region,

  \[
    Q(R).\text{minKey}() = \min \{ d(v) | \text{uv is a pending edge contained in R} \}
  \]
\end{corollary}

When the algorithm terminates, the minimum key of the priority queue associated with the entire graph will be infinity, and by corollary~\ref{cor:relaxed} all edges will be relaxed.

\subsubsection{Analysis}
\label{sec:analysis}

We show that dividing the graph into $\mathcal{O}(n/\log^4n)$ regions of size $\mathcal{O}(\log^4 n)$ with boundaries of size $\mathcal{O}(\log^2 n)$ and setting $\alpha_0 = 0, \alpha_1 = \log n$ and $\alpha_2 = 1$ yields an $\mathcal{O}(n \log \log n)$ single source shortest paths algorithm. The $\alpha_i$ are parameters that dictate how much speculative work we do in a region before moving on. Note that this division is simply an $r$-division with $r=\log^4 n$, and thus $r_0=1, r_1 = \log^4 n$, and $r_2 = n$.

We restate the algorithm:
\begin{enumerate}
\item Select the region containing the lowest labeled node that has active outgoing edges in the region.
\item Repeat $\log n$ times: Select the lowest labeled node $v$ in the current region that has active outgoing edges in the region. Relax and deactive its outgoing edges $vw$ in that region. For each of the other endpoints $w$ of these edges, if relaxing the edge $vw$ resulted in decreasing the label of $w$, then activate the outgoing edges of $w$.
\end{enumerate}

The majority of the time is spent in invocations of \textsc{Process}. We say that an invocation of \textsc{Process} on region $R$ is \emph{truncated} if $Q(R).minKey()$ is infinity at the end of the invocation. All level $0$ invocations are truncated. The crux of the analysis relies on the following \emph{charging invariant}:

\noindent\makebox[\textwidth][c]{%
\begin{minipage}{.8\textwidth}
  For any pair $(R,v)$ of region $R$ and entry node $v$, there is an invocation $B$ of \textsc{Process} such that all invocations charging to $(R,v)$ are descendants of $B$ (or $B$ itself).
\end{minipage}}

Intuitively, the \emph{charging invariant} says that the number of charges to any pair is small, so the number of truncated invocations will be small.

 Let us first consider the number of pairs $(R,v)$ on each level to which we can charge truncated invocations to (recall that $v$ is an entry node into $R$):
\begin{itemize}
\item If $R$ has level $0$, then $R$ is charged by at most one level $0$ invocation. There are $\mathcal{O}(n)$ pairs $(R,v)$ on level $0$, and thus $\mathcal{O}(n)$ chargers.
\item If $R$ has level $1$, the pair is charged by at most one level $1$ invocation and at most $\alpha_1 = \log n$ level $0$ invocations. There are $\mathcal{O}(n/\log^4n)\cdot O(\log^2 n)$ pairs on level $1$.
\item If $R$ has level $2$, then the pair is charged by at most one level $2$ invocation, at most $\alpha_2 = 1$ level $1$ invocations, and at most $\alpha_2\alpha_1 = \log n$ level $0$ invocations. There is only one pair $(R,v)$ on level $2$, namely $(R_G,s)$.
\end{itemize}

Let $s_i$ be the total number of invocations at level $i$ (truncated and non-truncated), and $t_i$ be the number of truncated chargers at level $i$.

All level $0$ invocations are truncated, thus
\[
s_0 = \mathcal{O}(n)
\]
 Each non-truncated level $j$ invocation results in $\alpha_j$ invocations at level $j-1$. Hence the number of level $1$ invocations is
\[
s_1 \leq s_0/\alpha_1 + t_1 = \mathcal{O}(n/\log n) + \mathcal{O}(n/\log^2 n).
\]
 Similarly, the total number of level $2$ invocations is
\[
s_2 \leq s_1/\alpha_2 + 1 = s_1 + 1 = \mathcal{O}(n/\log n).
\]

Let's look at the time spent per invocation at each level. We bound the time required per queue operation; since at level $i$ there are $\alpha_i$ calls to lower levels, and thus $\alpha_i$ queue operations, this gives us a time bound per invocation.

\begin{itemize}
\item At level $0$, there is only one item in the queue, so operations take constant time, and there are $\alpha_0 = 0$ calls to lower levels.
\item At level $1$, queues are of size $\mathcal{O}(log^4 n)$, so queue operations take $\mathcal{O}(\log \log n)$ time. There are $\alpha_1 = \log n$ calls to lower levels, for a total of $\mathcal{O}(\log n \log \log n)$.
\item At level $2$, queues are of size $\mathcal{O}(n/\log^4 n)$, so queue operations take $\mathcal{O}(\log n)$ time, and there are $\alpha_2 = 1$ calls to lower levels, for a total of $\mathcal{O}(\log n)$.
\end{itemize}

To get our total time bounds, we multiply the time per invocation with the number of invocations at each level, and add everything up.
\begin{align*}
  \text{Total} &= \mathcal{O}(\log n) \cdot \mathcal{O}(n/\log n) + \mathcal{O}(\log n \log \log n) \cdot \mathcal{O}(n/ \log n) + \mathcal{O}(1) \cdot \mathcal{O}(n) \\
               &= \mathcal{O}(n \log \log n)
\end{align*}
The information is summarized in table~\ref{tab:process}.


\begin{table*}[!h]\centering
\caption{Time required for \textsc{Process} calls.}
\label{tab:process}
\ra{1.3}
\begin{tabular}{@{}llllll@{}} \toprule
  Level & Calls & Time per invocation & No.\ $(R,v)$ pairs & No.\ invocations & Total time\\ \midrule
  $2$ & $1$ & $\mathcal{O}(\log n)$ & 1 & $\mathcal{O}(n/\log n)$ & $\mathcal{O}(n)$\\
  $1$ & $\log n$ & $\mathcal{O}(\log n \log \log n)$ & $\mathcal{O}(n/\log^2 n)$ & $\mathcal{O}(n/\log n)$ & $\mathcal{O}(n\log \log n)$\\
  $0$ & $0$ & $\mathcal{O}(1)$ & $\mathcal{O}(n)$ & $\mathcal{O}(n)$ & $\mathcal{O}(n)$\\ \midrule
  Total & & & & & $\mathcal{O}(n\log \log n)$\\
  \bottomrule
\end{tabular}
\end{table*}

The analysis bounds invocations of \textsc{Process}, but not those of \textsc{Update}. However, the analysis for \textsc{Update} follows the same direction and also yields a $\mathcal{O}(n \log \log n)$ time bound.

\subsubsection{Linear time}
\label{sec:linear-time}

To improve the running time to linear, we must use a recursive subdivision. Let $r_i$ be the size of the subregions on level $i$, and $\alpha_i$ be the number of iterations per invocation of \textsc{Process} for level $i$. Define
\[
  \alpha_i = \frac{4\log r_{i+1}}{3 \log r_i}
\]
with $\alpha_0 = 0$, and $\alpha_{h(G)} = 1$.

To achieve linear time, we define the $r_i$ inductively by $r_0 = 1$, and $r_{i+1} = 16^{r_i^{1/6}}$. This defines a division into roughly $\log^{*} n$ levels. The algorithm is given above, but we repeat it here for clarity:

\begin{algorithm}
  \begin{algorithmic}[1]
    \State Find recursive subdivision $R(G), R(P_i), \ldots, R(uv)$
    \State Allocate queue $Q$ for each region
    \State $d(v) \gets \infty, \forall v$
    \State $d(s) \gets 0$
    \ForAll {$sv \in E(G)$}
      \State \Call{Update}{$R(sv),sv,0$}
    \EndFor
    \While {$Q(R(G)).minKey() < \infty$}
      \State \Call{Process}{$R(G)$}
    \EndWhile
  \end{algorithmic}
\end{algorithm}


The correctness proof did not rely on the $\alpha_i$ or $r_i$ and follows from section~\ref{sec:correctness}. Using a very similar argument as in section~\ref{sec:analysis}, it is possible to show that the linear time bound holds for this choice of parameters, though the recursion is more involved.

\section{Single source shortest paths with arbitrary edge weights}
\label{sec:arbitr-edge-weights}

\textcolor{red}{This section is under construction. Our apologies.}

\subsection{Motivation}
\label{sec:arbitr-motiv}

Given the separator theorem of Lipton and Tarjan~\cite{lipton1979separator}, divide-and-conquer algorithms on planar graphs seem appealing: the fact that each part has many vertices adds only a factor of $\log n$ to the runtime of what we have to do in order to combine the two parts and furthermore the two parts have very little in common vertices, so now even slow algorithms as Bellman-Ford seem appealing. Actually, this is what we will do, although in order to get tighter bounds we will need an improved variant of Bellman-Ford, based on the special structure of planar graphs.

\subsection{Intuitive description}
\label{sec:intu-descr}


Let us now go more in depth into how the algorithms work, while still not touching the details, which we will touch in the next section. First of all, note that the vertex $s$ from which we want to find the distances might not be a boundary vertex, which will couse problems when we try to recurse. We can easily solve this, as if we have the distances from any other vertex, we can dene a price function which will make every edge positive and enable us to apply Dijkstra. We may therefore choose a boundary vertex. We now need to "glue" these the smallest distances we have. Note that we may glue only along the boundary cycle, i.e. any shortest path from $x$ to $y$ will have the following form: an inital and last segment, from x to the boundary cycle and from a vertex from the boundary cycle to $y$, and then a couple of other paths between vertices on the boundary cycle, paths which stay within one of the two parts. Therefore, it seems natural to try to compute the distances between vertices on the boundary (as they form the ``bulk'' of the $x-y$ path).

We already have the distances between two vertices on the boundary within each of the two parts (for proving the first part an algorithm of Klein that does exactly this is used). In order to combine these we will use Bellman-Ford, although a little modified. Note that for a convex quadrangle $ABCD$ we have that $AC + BD \geq AB + CD$. This seems trivial, but note that the lengths can take the value of any distance function, so also of the shortest path! This means that if we order the vertices on the boundary cyclically, there is special structure to this distance function. We will make this formal by using Monge matrices (note the equivalence of $AB + CD \leq AC + BD$ and $a_{ij} + a_{kl} \geq a_{il} + a_{kj}$ if $i \leq k$ and $j \leq l$). By what we said earlier, we only need to find the distances from a vertex on boundary to all the other vertces, and we can yet again, using the distances between boundary vertices, do this by using a price function and Dijkstra. This is how the $\mathcal{O}(n \log^2 n)$ algorithm works.

For the $\mathcal{O}(n \log^2 n/ \log \log n)$ algorithm, we need to make certain improvements. First of all, it is obvious that if we try using divide-and-conquer with only two subproblems we are most certain to fail, as there is no easy way of improving the steps in the previous algorithm to take less than $\mathcal{O}(n \log n)$. For this, we will use the separator theorem of Fakcharoenphol and Rao~\cite{fakcharoenphol2001planar}. This, however, brings about problems we didn’t have to face before, the most complicated of which are the holes. Note that, however, the separator theorem assures many useful properties, one of which is the constant number of holes. This might enable using algorithms for every pair of holes within a region (where region is a part of the division). Also, there aren’t many boundary nodes per region.


\section{Conclusion}
\label{sec:conclusion}

From integrated circuit design to network design to path-planning in robotics, planar graphs frequently occur in day-to-day life. By understanding the unique properties of planar graphs and how to exploit their structure, it is possible to address many of the common issues prevalent in many domains. The fundamental step in many planar graph algorithms is to find a smaller subset of the problem to solve first for a divide-and-conquer approach. Planar graph separators enable complex problems, such as shortest path, to be solved in an efficient manner. Expanding to application, shortest path represents one of the many canonical algorithms that can be applied to planar graphs. Like in their non-planar counterparts, shortest path can be used to address many real-world problems such as robotic navigation. Adding in negative edge costs allows for richer and more complex problems, such as shipping commodities through many different channels where profit effects may result in negative costs.

In this paper, we have presented the intuition behind algorithms for planar graph separators, non-negative single-source shortest path, and negative weight shortest path in planar graphs. We hope we have shown more clearly that restricting ourselves to certain classes of graphs can lead to beautiful, yet simple, solutions to many common problems.

\bibliographystyle{plain}
\bibliography{project}
\end{document}
